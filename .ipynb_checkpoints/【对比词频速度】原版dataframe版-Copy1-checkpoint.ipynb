{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344f4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def DataframeCleanUp(dataframe):\n",
    "    #删除content是空的那些行\n",
    "    dataframe = dataframe[dataframe['content'].notna()]\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "'''\n",
    "文本清洗\n",
    "@return text：清洗后的文本\n",
    "'''\n",
    "def process_text(text):\n",
    "    text = re.sub(r\"[0-9]+\", '', text) \n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    text = ''.join(e for e in text if e.isalnum())\n",
    "    return text\n",
    "\n",
    "\n",
    "'''\n",
    "文本清洗\n",
    "@param dataframe：数据来源dataframe\n",
    "@param row_to_clean：需要清洗的column\n",
    "@return dataframe：清洗后的dataframe，加了一列clean_cmt为清洗后的文本\n",
    "'''\n",
    "def SentenceCleanUp(dataframe, row_to_clean):\n",
    "    content = dataframe[row_to_clean].dropna() #把空的content去掉\n",
    "    processed_content = []\n",
    "    for i in range(len(content)):\n",
    "        processed_content.append([process_text(content.iloc[i])])\n",
    "    dataframe[\"clean_cmt\"] = np.array(processed_content) \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "'''\n",
    "文本清洗\n",
    "@return stopwordlist\n",
    "'''\n",
    "def makeStopWords(wordfile):\n",
    "    stopwords = wordfile[wordfile['Unnamed: 2'] == 1]\n",
    "    stopwordlist = list(stopwords['Unnamed: 0'])\n",
    "    stopwordlist.extend(['飞吻','笑哭','偷笑','哭惹','派对','微笑','害羞']) #加入额外的自定义stopwords\n",
    "\n",
    "    return stopwordlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d142dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.756 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      brand_code word  count\n",
      "0         164622   衣服  227.0\n",
      "1         164622   国潮  195.0\n",
      "2         164622   裤子  184.0\n",
      "3         164622   外套  183.0\n",
      "4         164622   同款  181.0\n",
      "...          ...  ...    ...\n",
      "3832      164622   无脑    1.0\n",
      "3833      164622   无趣    1.0\n",
      "3834      164622   日益    1.0\n",
      "3835      164622   产生    1.0\n",
      "3836      164622   龙金    1.0\n",
      "\n",
      "[3837 rows x 3 columns]\n",
      "此品牌跑了 204.1215 seconds\n",
      "当前进度： 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab5ae0790578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m###开始时间\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetComments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#挑出对应文本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjiebaAnalyzeContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopwordlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMakeResultDataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##创立对应的dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ab5ae0790578>\u001b[0m in \u001b[0;36mgetComments\u001b[0;34m(brand, dataframe)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetComments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mbrand_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbrand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brand'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#将所有是此品牌的row摘出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mbrand_contents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_cmt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#将品牌对应的品论文本摘出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \"\"\"\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2724\u001b[0m     \u001b[0;31m# Ensure that we don't allow PandasArray / PandasDtype in internals.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m     \u001b[0;31m# For now, blocks should be backed by ndarrays when possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCPandasArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse as analyse\n",
    "\n",
    "\n",
    "'''\n",
    "@param: N/A\n",
    "@return brand_code_matching：品牌名和品牌code对应字典\n",
    "'''\n",
    "def brandDictionary():\n",
    "    code_form = pd.read_excel('tbl_brand.xlsx', engine='openpyxl')\n",
    "    brand_code_matching={}  ##品牌名和品牌code的对应字典\n",
    "    for brand in code_form['name']: \n",
    "        row_index = code_form.index[code_form['name'] == brand].tolist()\n",
    "        brand_code_matching[brand] = code_form.at[row_index[0],'code']\n",
    "    return brand_code_matching\n",
    "\n",
    "\n",
    "'''\n",
    "@param: 品牌名\n",
    "@return brandCode：品牌code\n",
    "'''\n",
    "def getBrandCode(brandName):\n",
    "    brand_code_dict = brandDictionary()\n",
    "    brandCode = brand_code_dict[brandName] \n",
    "    return brandCode\n",
    "\n",
    "'''\n",
    "创立2D array的function\n",
    "'''\n",
    "def init_list_of_objects(size):\n",
    "    list_of_objects = list()\n",
    "    for i in range(0,size):\n",
    "        list_of_objects.append( list() ) #different object reference each time\n",
    "    return list_of_objects\n",
    "\n",
    "\n",
    "'''\n",
    "@param brand: 品牌名\n",
    "@param dataframe: 数据来源dataframe\n",
    "@return brand_content：list；此品牌下所有评论文本\n",
    "'''\n",
    "def getComments(brand, dataframe):\n",
    "    brand_contents = []\n",
    "    for index,row in dataframe.iterrows():\n",
    "        if brand in str(row['brand']):  #将所有是此品牌的row摘出\n",
    "            brand_contents.append(row['clean_cmt']) #将品牌对应的品论文本摘出\n",
    "    return brand_contents\n",
    "\n",
    "'''\n",
    "@param contents: list; 品牌评论文本list\n",
    "@param stopwordlist: 定义的stopwords\n",
    "@return jieba_results：list；此品牌下所有评论的jieba分词结果\n",
    "'''\n",
    "def jiebaAnalyzeContents(contents, stopwordlist):\n",
    "    jieba_results = []\n",
    "    allow_pos = ('na') #选出形容词&名词\n",
    "    for i in range(len(contents)): #loop品牌1的每一条评论\n",
    "        lines = contents[i].split()\n",
    "        content1 = \"\".join(lines)\n",
    "        words = jieba.analyse.extract_tags(content1, topK=50, withWeight=False, allowPOS=(allow_pos))\n",
    "        for w in words:\n",
    "            if w in stopwordlist:\n",
    "                words.remove(w)\n",
    "        jieba_results.append([i,\",\".join(words)])\n",
    "    return jieba_results\n",
    "\n",
    "'''\n",
    "@param jieba_results：list；此品牌下所有评论的jieba分词结果\n",
    "@return dfwordcount: 高频词&频率的dataframe\n",
    "'''\n",
    "def countWords(jieba_results):\n",
    "    dfjieba0 = pd.DataFrame(jieba_results) #将第一个品牌的分词结果创一个dataframe\n",
    "    jieba_results = dfjieba0[1] #更新jieba0为仅有关键词，无index（用dfjieba0中关键词那一列）\n",
    "    dfseperate = jieba_results.str.split(',', expand=True) #只提取关键词那一列\n",
    "    for i in range (len(dfseperate)-1):\n",
    "        if i == 0:\n",
    "            df1 = pd.DataFrame(dfseperate.T[i].value_counts())\n",
    "        else:\n",
    "            df1 = df\n",
    "        df2 = pd.DataFrame(dfseperate.T[i+1].value_counts())\n",
    "        df = pd.DataFrame(df1.groupby(df1.index).sum().add(df2.groupby(df2.index).sum(), fill_value=0).sum(axis=1))\n",
    "\n",
    "    dfwordcount = df.sort_values(by = 0, ascending=False)\n",
    "\n",
    "    return dfwordcount\n",
    "\n",
    "'''\n",
    "用一个品牌的 contents & results 创立一个dataframe\n",
    "@param brand: 品牌名\n",
    "@param brand_content：list；此品牌下所有评论文本\n",
    "@param brand_results: list；此品牌下所有评论的星级打分\n",
    "'''\n",
    "def MakeResultDataframe(brand, jieba_results):\n",
    "    mydf=pd.DataFrame(columns={'brand_code','word','count'})\n",
    "\n",
    "    dfwordcount = countWords(jieba_results)\n",
    "    mydf['word']=dfwordcount.index ###word列为dfwordcount的index column（高频词列）\n",
    "    mydf['count']=dfwordcount.iloc[:,0].values ###count列为dfwordcount的0th column（词频统计列）\n",
    "\n",
    "    mydf['brand_code']= getBrandCode(brand) \n",
    "    mydf = mydf[['brand_code','word','count']]  #整理列的呈现顺序\n",
    "\n",
    "    return mydf\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dfred=pd.read_csv('red_top1000.csv')\n",
    "    brands_total = dfred['brand'].unique() #列出总共有多少个不同品牌（unique values of the brand column）\n",
    "\n",
    "    dfred = DataframeCleanUp(dfred)  #做dataframe的清理\n",
    "    dfred = SentenceCleanUp(dfred, 'content') #做content列的文本清理\n",
    "\n",
    "    wordfile = pd.read_excel('red_words.xlsx',engine = 'openpyxl')\n",
    "    stopwordlist = makeStopWords(wordfile)\n",
    "\n",
    "    #total_df=pd.DataFrame(columns={'brand_code','word','count'})\n",
    "    total_df=pd.DataFrame()\n",
    "\n",
    "    total, cnt = len(brands_total), 0\n",
    "    \n",
    "    for brand in brands_total: #每一个品牌\n",
    "        tic = time.perf_counter() ###开始时间\n",
    "        cnt += 1\n",
    "        contents = getComments(brand, dfred) #挑出对应文本\n",
    "        results=jiebaAnalyzeContents(contents, stopwordlist)\n",
    "        results_df = MakeResultDataframe(brand, results) ##创立对应的dataframe\n",
    "        \n",
    "        total_df = pd.concat([total_df, results_df], axis=0) #append在total_df下面\n",
    "        total_df = total_df[['brand_code','word','count']]  #整理列的呈现顺序\n",
    "        print(total_df)\n",
    "        total_df.to_excel(\"小红书品牌1000词频统计.xlsx\")\n",
    "        toc = time.perf_counter() ###结束时间\n",
    "        print(f\"此品牌跑了 {toc - tic:0.4f} seconds\")\n",
    "        print('当前进度：', cnt/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28dea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
